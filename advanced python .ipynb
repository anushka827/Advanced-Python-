{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOzAftIOmPv20jJ8TyAWJgB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anushka827/Advanced-Python-/blob/main/advanced%20python%20.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**PART-1 process automation**"
      ],
      "metadata": {
        "id": "NZnAeH3ipQ2Q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q1. create a line that contain 1000 lines of random strings"
      ],
      "metadata": {
        "id": "Wx1inirKphTe"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NQxNFPBFpOkg",
        "outputId": "6c048db5-2500-476e-8e30-6718ba909057"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File file.txt created with 1000 lines of random strings.\n"
          ]
        }
      ],
      "source": [
        "import random as r\n",
        "import string as s\n",
        "\n",
        "with open(\"file.txt\",\"w\") as f:\n",
        "  for _ in range(1000):\n",
        "    length=r.randint(5,20)\n",
        "    letters=s.ascii_letters\n",
        "    rand_string=\"\".join(r.choices(letters,k=length))\n",
        "    f.write(rand_string+'\\n')\n",
        "print(\"File file.txt created with 1000 lines of random strings.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q2.create lines that contain multiple lines of random strings and file size must be 5MB"
      ],
      "metadata": {
        "id": "41VVSonNqCa-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "with open(\"string.txt\",\"w\") as f:\n",
        "  size_mb=0\n",
        "  while size_mb<=5:\n",
        "    length=r.randint(5,20)\n",
        "    letters=s.ascii_letters\n",
        "    rand_string=\"\".join(r.choices(letters,k=length))\n",
        "    f.write(rand_string+'\\n')\n",
        "    size_bytes = os.path.getsize('/content/string.txt')\n",
        "    size_mb = size_bytes / (1024 * 1024)"
      ],
      "metadata": {
        "id": "CDZeX657r3B5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q3. create 10 files that contains multiple lines of random strings and file of each file must be 5MB"
      ],
      "metadata": {
        "id": "M-yN1472sBNE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "size_mb=5*1024*1024\n",
        "for i in range(0,10):\n",
        "  filename=f\"file+{i+1}.txt\"\n",
        "  with open(filename,'w') as f:\n",
        "    curr_size=0\n",
        "    while curr_size<=size_mb:\n",
        "       length=r.randint(5,20)\n",
        "       letters=s.ascii_letters\n",
        "       rand_string=\"\".join(r.choices(letters,k=length))\n",
        "       f.write(rand_string+'\\n')\n",
        "       curr_size += len(rand_string.encode('utf-8'))"
      ],
      "metadata": {
        "id": "Xc2TD3VZsbgA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q4. Create 5 files of size 1GB, 2GB, 3GB, 4GB and 5GB; file contains multiple lines of random strings."
      ],
      "metadata": {
        "id": "EfuJ9XLhtL0c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(1,6):\n",
        "  filename=f'f_{i}.txt'\n",
        "  size=i*1024*1024*1024\n",
        "  with open(filename,'w') as f:\n",
        "    curr_size=0\n",
        "    while curr_size<=size:\n",
        "      length=r.randint(5,20)\n",
        "      letters=s.ascii_letters\n",
        "      rand_string=\"\".join(r.choices(letters,k=length))\n",
        "      f.write(rand_string+'\\n')\n",
        "      curr_size += len(rand_string.encode('utf-8'))"
      ],
      "metadata": {
        "id": "7W_vzCWos-TB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q5. Convert all the files of Q4 into upper case one by one."
      ],
      "metadata": {
        "id": "R2HuKJb-tkAu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(1, 6):\n",
        "    filename = f'f_{i}.txt'\n",
        "    with open(filename, 'r') as f:\n",
        "        lines = f.readlines()\n",
        "    with open(filename, 'w') as f:\n",
        "        for line in lines:\n",
        "            f.write(line.upper())\n"
      ],
      "metadata": {
        "id": "wOkRPphHtr_7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q6. Convert all the files of Q4 into upper case parallel using multi-threading."
      ],
      "metadata": {
        "id": "3xNNLnN0tyfX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import threading\n",
        "\n",
        "def convert_file_to_upper(filename):\n",
        "    temp_filename = f\"temp_{filename}\"\n",
        "    with open(filename, 'r') as infile, open(temp_filename, 'w') as outfile:\n",
        "        for line in infile:\n",
        "            outfile.write(line.upper())\n",
        "    os.replace(temp_filename, filename)\n",
        "\n",
        "threads = []\n",
        "for i in range(1, 6):\n",
        "    filename = f\"f_{i}.txt\"\n",
        "    t = threading.Thread(target=convert_file_to_upper, args=(filename,))\n",
        "    t.start()\n",
        "    threads.append(t)\n",
        "\n",
        "for t in threads:\n",
        "    t.join()\n",
        "\n",
        "print(\"All files converted to uppercase using multithreading.\")"
      ],
      "metadata": {
        "id": "dQSIOR-St5D-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q7. wap to download 10 images of cat using google lens"
      ],
      "metadata": {
        "id": "9FrgjhPqvz9i"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q8. wap to download 10 videos of machine learning from youtube"
      ],
      "metadata": {
        "id": "dnSwYv2-xWoV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import os\n",
        "from yt_dlp import YoutubeDL\n",
        "from youtube_search import YoutubeSearch\n",
        "\n",
        "print(\"--- Installing required libraries ---\")\n",
        "!pip install -q yt-dlp\n",
        "\n",
        "!pip install -q youtube-search-python\n",
        "print(\"--- Installation complete ---\")\n",
        "\n",
        "SEARCH_QUERY = \"machine learning\"\n",
        "NUM_VIDEOS_TO_DOWNLOAD = 10\n",
        "\n",
        "OUTPUT_DIR = \"ml_videos\"\n",
        "\n",
        "if not os.path.exists(OUTPUT_DIR):\n",
        "    os.makedirs(OUTPUT_DIR)\n",
        "    print(f\"Created directory: {OUTPUT_DIR}\")\n",
        "\n",
        "\n",
        "print(f\"\\n--- Searching for top {NUM_VIDEOS_TO_DOWNLOAD} '{SEARCH_QUERY}' videos on YouTube ---\")\n",
        "try:\n",
        "    results = YoutubeSearch(SEARCH_QUERY, max_results=NUM_VIDEOS_TO_DOWNLOAD).to_dict()\n",
        "\n",
        "    video_urls = [f\"https://www.youtube.com/watch?v={video['id']}\" for video in results['videos']]\n",
        "\n",
        "    if not video_urls:\n",
        "        print(\"No video URLs found for the given search query. Exiting.\")\n",
        "    else:\n",
        "        print(f\"Found {len(video_urls)} video URLs.\")\n",
        "        for i, url in enumerate(video_urls):\n",
        "            print(f\"{i+1}. {url}\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred during video search: {e}\")\n",
        "    video_urls = []\n",
        "\n",
        "if video_urls:\n",
        "    print(f\"\\n--- Starting download of {len(video_urls)} videos ---\")\n",
        "\n",
        "    ydl_opts = {\n",
        "        'format': 'bestvideo[ext=mp4]+bestaudio[ext=m4a]/best[ext=mp4]/best',\n",
        "        'outtmpl': os.path.join(OUTPUT_DIR, '%(title)s.%(ext)s'),\n",
        "        'noplaylist': True,\n",
        "        'quiet': False,\n",
        "        'no_warnings': True,\n",
        "    }\n",
        "\n",
        "    with YoutubeDL(ydl_opts) as ydl:\n",
        "        for i, url in enumerate(video_urls):\n",
        "            print(f\"\\n--- Downloading video {i+1}/{len(video_urls)}: {url} ---\")\n",
        "            try:\n",
        "                ydl.download([url])\n",
        "                print(f\"Successfully downloaded: {url}\")\n",
        "            except Exception as e:\n",
        "                print(f\"Error downloading {url}: {e}\")\n",
        "else:\n",
        "    print(\"No videos to download as no URLs were found or search failed.\")\n",
        "\n",
        "print(\"\\n--- All requested operations complete ---\")\n",
        "print(f\"You can find the downloaded videos in the '{OUTPUT_DIR}' folder in your Colab files sidebar.\")\n"
      ],
      "metadata": {
        "id": "2w5z-4n4ydvD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q9. Convert all the videos of Q8 and convert it to audio."
      ],
      "metadata": {
        "id": "feeY-r1f056E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from moviepy.editor import VideoFileClip\n",
        "\n",
        "folder = \"ml_vids\"\n",
        "output_folder = \"ml_audios\"\n",
        "os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "for filename in os.listdir(folder):\n",
        "    if filename.lower().endswith(('.mp4', '.mkv', '.webm')):\n",
        "        video_path = os.path.join(folder, filename)\n",
        "        audio_filename = os.path.splitext(filename)[0] + \".mp3\"\n",
        "        audio_path = os.path.join(output_folder, audio_filename)\n",
        "\n",
        "        try:\n",
        "            print(f\"Converting: {filename}\")\n",
        "            clip = VideoFileClip(video_path)\n",
        "            clip.audio.write_audiofile(audio_path)\n",
        "            clip.close()\n",
        "        except Exception as e:\n",
        "            print(f\"Failed to convert {filename}: {e}\")\n"
      ],
      "metadata": {
        "id": "AgcFYuhV1FPO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}